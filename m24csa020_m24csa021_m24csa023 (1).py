# -*- coding: utf-8 -*-
"""M24CSA020_M24CSA021_M24CSA023.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HCUQTQhh8mI9bvd-z8uIz60TlCfctdAX

**Image Segmentation for Biomedical Applications**



**Submitted By**

**Pooja Naveen Poonia M24CSA020**

**Pranjal Malik M24CSA021**

**Prathmesh Chintamani Gosavi M24CSA023**

---
"""

!pip install imagecodecs

!pip install imageio scikit-image matplotlib opencv-python

"""**Implemented Adaptive thresholding and Edge based segmentations like Canny and Sobel edge detection.**


"""

from pickle import NONE
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
from skimage.segmentation import watershed, active_contour
from skimage.filters import threshold_local, sobel
from skimage.feature import canny
from skimage.measure import label
from PIL import Image
from skimage.morphology import disk
from scipy import ndimage as ndi
from IPython.display import display
from skimage.filters import threshold_otsu
from skimage.segmentation import morphological_chan_vese
from skimage.draw import polygon
from skimage import img_as_float
from skimage.filters import sobel
from skimage.draw import polygon
from skimage.segmentation import active_contour

#  Step 1: Mount Google Drive
drive.mount('/content/drive', force_remount=True)

#  Step 2: Define dataset paths
image_dir = "/content/drive/MyDrive/dia_project/training_extracted/training/images"
mask_dir = "/content/drive/MyDrive/dia_project/training_extracted/training/mask"
manual_dir = "/content/drive/MyDrive/dia_project/training_extracted/training/1st_manual"

#  Step 3: List available images, masks & manual segmentations
image_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith('.tif')])
mask_files = sorted([f for f in os.listdir(mask_dir) if f.lower().endswith('.gif')])
manual_files = sorted([f for f in os.listdir(manual_dir) if f.lower().endswith('.gif')])

print(" Found Images:", image_files)
print(" Found Masks:", mask_files)
print(" Found Manual Segmentations:", manual_files)

#  Step 4: Ensure images have corresponding masks & manual segmentations
valid_images = []
image_mask_manual_map = {}

for img in image_files:
    base_name = img.replace('_training.tif', '')
    corresponding_mask = f"{base_name}_training_mask.gif"
    corresponding_manual = f"{base_name}_manual1.gif"

    if corresponding_mask in mask_files and corresponding_manual in manual_files:
        valid_images.append(img)
        image_mask_manual_map[img] = (corresponding_mask, corresponding_manual)

if not valid_images:
    raise FileNotFoundError(" No valid image-mask-manual triplets found! Check dataset paths and naming conventions.")

# Step 5: Select the first available image-mask-manual triplet
image_filename = valid_images[0]
mask_filename, manual_filename = image_mask_manual_map[image_filename]

image_path = os.path.join(image_dir, image_filename)
mask_path = os.path.join(mask_dir, mask_filename)
manual_path = os.path.join(manual_dir, manual_filename)

print(f" Processing Image: {image_filename} with Mask: {mask_filename} and Manual Segmentation: {manual_filename}")

# Load an image (TIFF)
def load_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise FileNotFoundError(f"Error: Unable to load image at {image_path}")
    return img

# Load a mask (GIF)
def load_mask(mask_path):
    mask = Image.open(mask_path).convert("L")
    mask = np.array(mask)
    return mask

# Load manual annotation mask (GIF)
def load_manual(manual_path):
    manual = Image.open(manual_path).convert("L")
    manual = np.array(manual)
    return manual

# Compute Dice Similarity Coefficient
def dice_coefficient(segmented_mask, manual_mask):
    intersection = np.logical_and(segmented_mask, manual_mask).sum()
    total_pixels = segmented_mask.sum() + manual_mask.sum()
    return (2 * intersection) / total_pixels if total_pixels > 0 else 0

# A. Mask the Circular Retina Area Before Segmentation
def mask_retina(image):
    h, w = image.shape
    center = (w // 2, h // 2)
    radius = min(center[0], center[1], w - center[0], h - center[1])
    Y, X = np.ogrid[:h, :w]
    dist_from_center = np.sqrt((X - center[0])**2 + (Y - center[1])**2)
    circular_mask = dist_from_center <= radius
    masked_image = np.zeros_like(image)
    masked_image[circular_mask] = image[circular_mask]
    return masked_image

# Edge-Based Segmentation Techniques
def sobel_edge_detection(image):
    # Apply Sobel edge detection filter
    edges = sobel(image)
    return edges

def canny_edge_detection(image):
    # Apply Canny edge detection filter
    edges = canny(image)
    return edges

def watershed_segmentation(image):
    # Apply Sobel filter to find gradients
    gradient = sobel(image)

    # Threshold the gradient image
    markers = ndi.label(gradient < 0.2)[0]

    # Apply Watershed segmentation
    segmented_image = watershed(gradient, markers)
    return segmented_image

# 1. Adaptive Thresholding
def preprocess_image(image):
    if len(image.shape) == 3:
        gray = color.rgb2gray(image)
        gray = (gray * 255).astype(np.uint8)
    else:
        gray = image.astype(np.uint8) if image.dtype != np.uint8 else image
    if gray.dtype == np.uint16:
        gray = (gray / 256).astype(np.uint8)

    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)
    return blurred

def segment_dark_regions(image):
    thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY_INV, 11, 2)
    kernel = np.ones((3, 3), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
    return cleaned

def adaptive_thresholding(image, mask):

    # Step 1: Preprocess the image
    preprocessed_image = preprocess_image(image)

    # Step 2: Segment dark regions using adaptive thresholding
    dark_regions = segment_dark_regions(preprocessed_image)

    enhanced = cv2.bitwise_and(dark_regions, dark_regions, mask=mask)

    return dark_regions, enhanced, preprocessed_image, mask

# Display results
def display_results(image, mask, binary_image, region_grow_result, watershed_result, active_contour_result, sobel_edges, canny_edges):
    fig, axes = plt.subplots(1, 5, figsize=(20, 5))
    axes[0].imshow(image, cmap='gray')
    axes[0].set_title("Original Image")

    axes[1].imshow(mask, cmap='gray')
    axes[1].set_title("Ground Truth Mask (GIF)")

    axes[2].imshow(binary_image, cmap='gray')
    axes[2].set_title("Adaptive Thresholding")

    axes[3].imshow(watershed_result, cmap='nipy_spectral')
    axes[3].set_title("Watershed Segmentation")

    axes[4].imshow(sobel_edges, cmap='gray')
    axes[4].set_title("Sobel Edges")

    plt.show()

# Main function
def process_all_images():
    dice_region, dice_watershed = [], []
    dice_adaptive, dice_otsu, dice_snake, dice_chanvese = [], [], [], []

    for idx, image_filename in enumerate(valid_images):
        print(f"\n Processing [{idx+1}/{len(valid_images)}]: {image_filename}")
        mask_filename, manual_filename = image_mask_manual_map[image_filename]

        image_path = os.path.join(image_dir, image_filename)
        mask_path = os.path.join(mask_dir, mask_filename)
        manual_path = os.path.join(manual_dir, manual_filename)

        image = load_image(image_path)
        mask = load_mask(mask_path)
        manual_mask = load_manual(manual_path)

        # Retina masking
        retina_mask = create_retina_mask(image.shape)
        image = cv2.bitwise_and(image, image, mask=retina_mask)

        # Segmentations
        adaptive, enhanced, raw_thresh, extra_value = adaptive_thresholding(image, mask)
        adaptive = adaptive.astype(np.uint8)

        # Edge-Based Segmentation
        sobel_edges = sobel_edge_detection(image)
        canny_edges = canny_edge_detection

def main():
    # Step 1: Process all images and perform segmentation
    print(" Starting Image Processing...")

    # Process all images in the dataset
    process_all_images()

    print("\n Running Edge-Based Segmentation (Canny, Sobel) and Adaptive Thresholding...")

    for idx, image_filename in enumerate(valid_images):
        print(f"\n Processing [{idx+1}/{len(valid_images)}]: {image_filename}")
        mask_filename, manual_filename = image_mask_manual_map[image_filename]

        image_path = os.path.join(image_dir, image_filename)
        mask_path = os.path.join(mask_dir, mask_filename)
        manual_path = os.path.join(manual_dir, manual_filename)

        image = load_image(image_path)
        mask = load_mask(mask_path)
        manual_mask = load_manual(manual_path)

        # Retina masking
        retina_mask = create_retina_mask(image.shape)
        image = cv2.bitwise_and(image, image, mask=retina_mask)

        # Edge-based Segmentation (Canny and Sobel)
        # Apply Canny Edge Detection
        edges_canny = canny(image / 255.0)

        # Apply Sobel Edge Detection
        edges_sobel = sobel(image / 255.0)

        # Perform Adaptive Thresholding with Preprocessing and Dark Region Segmentation
        adaptive, enhanced, preprocessed_image, refined_mask = adaptive_thresholding(image, mask)
        adaptive = adaptive.astype(np.uint8)

        # Display Results for Edge Detection and Adaptive Thresholding
        fig, axes = plt.subplots(1, 5, figsize=(25, 5))
        axes[0].imshow(image, cmap='gray')
        axes[0].set_title("Original Image")
        axes[0].axis("off")

        axes[1].imshow(mask, cmap='gray')
        axes[1].set_title("Ground Truth Mask")
        axes[1].axis("off")

        axes[2].imshow(edges_canny, cmap='gray')
        axes[2].set_title("Canny Edge Detection")
        axes[2].axis("off")

        axes[3].imshow(edges_sobel, cmap='gray')
        axes[3].set_title("Sobel Edge Detection")
        axes[3].axis("off")

        axes[4].imshow(adaptive, cmap='gray')
        axes[4].set_title("Adaptive Thresholding")
        axes[4].axis("off")

        plt.suptitle(f"Segmentation Results for {image_filename}", fontsize=16)
        plt.tight_layout()
        plt.show()

if __name__ == "__main__":
    main()

"""**Implemented Watershed Segmentation Technique.**"""

for image_filename in valid_images:
    mask_filename, manual_filename = image_mask_manual_map[image_filename]

    # Full paths
    image_path = os.path.join(image_dir, image_filename)
    mask_path = os.path.join(mask_dir, mask_filename)
    manual_path = os.path.join(manual_dir, manual_filename)

    print(f" Processing: {image_filename}")

    # Load images
    image = cv2.imread(image_path)
    mask = load_mask(mask_path)
    manual = load_manual(manual_path)

    #  Step 1: Apply binary mask to isolate retina
    masked_image = cv2.bitwise_and(image, image, mask=mask)

    #  Step 2: LAB + CLAHE Enhancement
    lab = cv2.cvtColor(masked_image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    lab = cv2.merge((cl, a, b))
    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

    #  Step 3: Convert to grayscale
    gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)

    # Step 4: Top-Hat Morphological Filtering
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)
    gray_enhanced = cv2.add(gray, tophat)

    # Step 5: Gaussian Blur + Otsu Thresholding
    blurred = cv2.GaussianBlur(gray_enhanced, (5, 5), 0)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Step 6: Morphological Opening
    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=2)

    # Step 7: Sure Background
    sure_bg = cv2.dilate(opening, np.ones((3, 3), np.uint8), iterations=3)
    sure_bg = cv2.bitwise_and(sure_bg, sure_bg, mask=mask)

    # Step 8: Distance Transform + Foreground Threshold
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, 0.25 * dist_transform.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)

    # Step 9: Unknown Region
    unknown = cv2.subtract(sure_bg, sure_fg)

    # Step 10: Connected Components
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0

    # Step 11: Watershed
    watershed_result = image.copy()
    markers = cv2.watershed(watershed_result, markers)
    watershed_result[markers == -1] = [0, 255, 0]

    # Step 12: Edge Overlay (Optional)
    edges = cv2.Canny(gray, 100, 200)
    edge_overlay = np.zeros_like(image)
    edge_overlay[edges != 0] = [0, 255, 255]
    blended = cv2.addWeighted(watershed_result, 0.7, edge_overlay, 0.3, 0)

    # Plot Original, Mask, Manual, and Segmentation Result
    plt.figure(figsize=(16, 10))

    plt.subplot(1, 4, 1)
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title("Original Image")
    plt.axis("off")

    plt.subplot(1, 4, 2)
    plt.imshow(mask, cmap='gray')
    plt.title("Binary Mask")
    plt.axis("off")

    plt.subplot(1, 4, 3)
    plt.imshow(manual, cmap='gray')
    plt.title("Manual Annotation")
    plt.axis("off")

    plt.subplot(1, 4, 4)
    plt.imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))
    plt.title("Watershed + Edges")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

"""**Implemented Region growing segmentation using overlays by calculationg dynamic threshold value.**"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, accuracy_score
import pandas as pd
import seaborn as sns

def region_grow(image, seed_point, threshold, mask=None):
    h, w = image.shape
    visited = np.zeros((h, w), dtype=bool)
    region = np.zeros((h, w), dtype=np.uint8)
    seed_val = image[seed_point[1], seed_point[0]]

    stack = [seed_point]
    while stack:
        x, y = stack.pop()
        if visited[y, x]:
            continue
        visited[y, x] = True
        diff = abs(int(image[y, x]) - int(seed_val))
        if diff <= threshold:
            region[y, x] = 255
            for dx in [-1, 0, 1]:
                for dy in [-1, 0, 1]:
                    nx, ny = x + dx, y + dy
                    if 0 <= nx < w and 0 <= ny < h and not visited[ny, nx]:
                        if mask is None or mask[ny, nx] > 0:
                            stack.append((nx, ny))
    return region

def auto_region_grow(image, manual_mask, seed_point, growth_mask, thresholds=range(20, 61, 5)):
    best_region = None
    best_score = -1
    best_t = None

    # Binarize manual for evaluation
    _, manual_bin = cv2.threshold(manual_mask, 127, 1, cv2.THRESH_BINARY)

    for t in thresholds:
        region = region_grow(image, seed_point, t, mask=growth_mask)
        _, region_bin = cv2.threshold(region, 127, 1, cv2.THRESH_BINARY)

        intersection = np.logical_and(region_bin, manual_bin).sum()
        union = np.logical_or(region_bin, manual_bin).sum()

        score = intersection / union if union > 0 else 0

        if score > best_score:
            best_score = score
            best_region = region
            best_t = t

    if best_t is None:
        best_t = thresholds[0]

    print(f" Best threshold for this image: {best_t}")
    return best_region, best_t

# Initialize
all_preds = []
all_trues = []
image_thresholds = {}

# Process all images
for image_filename in valid_images:
    mask_filename, manual_filename = image_mask_manual_map[image_filename]

    fundus_path = os.path.join(image_dir, image_filename)
    manual_path = os.path.join(manual_dir, manual_filename)

    fundus = cv2.imread(fundus_path)
    fundus_rgb = cv2.cvtColor(fundus, cv2.COLOR_BGR2RGB)
    manual = np.array(Image.open(manual_path).convert("L"))
    gray = cv2.cvtColor(fundus_rgb, cv2.COLOR_RGB2GRAY)

    ys, xs = np.where(manual > 0)
    if len(xs) == 0:
        print(f" No vessel pixels in {manual_filename}")
        continue

    rand_index = np.random.randint(0, len(xs))
    seed_point = (xs[rand_index], ys[rand_index])

    growth_mask = cv2.dilate(manual, np.ones((3, 3), np.uint8), iterations=1)

    region, best_t = auto_region_grow(gray, manual, seed_point, growth_mask)
    image_thresholds[image_filename] = best_t

    region = cv2.morphologyEx(region, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))
    region = cv2.morphologyEx(region, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))

    if region.shape != manual.shape:
        manual = cv2.resize(manual, (region.shape[1], region.shape[0]))

    _, region_bin = cv2.threshold(region, 127, 1, cv2.THRESH_BINARY)
    _, manual_bin = cv2.threshold(manual, 127, 1, cv2.THRESH_BINARY)

    all_preds.append(region_bin.flatten())
    all_trues.append(manual_bin.flatten())

    # Visualization
    overlay = fundus_rgb.copy()
    overlay[region_bin > 0] = [255, 0, 0]

    fig, axes = plt.subplots(1, 4, figsize=(20, 5))
    axes[0].imshow(fundus_rgb)
    axes[0].set_title("Original Fundus")
    axes[1].imshow(region, cmap='gray')
    axes[1].set_title(f"Region Growing (Threshold: {best_t})")
    axes[2].imshow(manual, cmap='gray')
    axes[2].set_title("Manual Mask")
    axes[3].imshow(overlay)
    axes[3].set_title("Overlay")
    for ax in axes:
        ax.axis("off")
    plt.tight_layout()
    plt.show()

# Metrics
y_pred = np.concatenate(all_preds)
y_true = np.concatenate(all_trues)

precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
jaccard = jaccard_score(y_true, y_pred)
accuracy = accuracy_score(y_true, y_pred)

print("\n Region Growing Segmentation Metrics (Overall):")
print(f"Precision : {precision:.4f}")
print(f"Recall    : {recall:.4f}")
print(f"F1 Score  : {f1:.4f}")
print(f"Jaccard   : {jaccard:.4f}")
print(f"Accuracy  : {accuracy:.4f}")

# Threshold analysis
threshold_df = pd.DataFrame(list(image_thresholds.items()), columns=["Image", "Best_Threshold"])
print("\n Best Thresholds per Image:")
print(threshold_df)

plt.figure(figsize=(8, 4))
sns.histplot(threshold_df["Best_Threshold"], bins=range(20, 65, 5), kde=True)
plt.title("Distribution of Best Thresholds per Image")
plt.xlabel("Threshold Value")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

print(f"\n Mean Threshold: {threshold_df['Best_Threshold'].mean():.2f}")
print(f" Most Common Threshold: {threshold_df['Best_Threshold'].mode()[0]}")